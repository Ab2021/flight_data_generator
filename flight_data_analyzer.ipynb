{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1sys3ticCgZ",
        "outputId": "9158963c-635a-451f-94da-3eb99a1093c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Python_Scripts/Assignments/vertisystem\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/Python_Scripts/Assignments/vertisystem/\")\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XKeA4EnurSTh"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Flight Data Generator and Analyzer\n",
        "\n",
        "This script generates synthetic flight data and performs analysis\n",
        "It creates a large no. of JSON files containing randomized flight records,\n",
        "then analyzes these files to extract various statistics about the flights\n",
        "\n",
        "Key features:\n",
        "1. Generation of synthetic flight data\n",
        "2. Multithreaded file generation for improved performance\n",
        "3. Parallel processing for file analysis\n",
        "4. Analysis of generated data, including:\n",
        "   - Total no. of records and \"miss\" (incomplete) records\n",
        "   - Average and 95th percentile flight durations for top destinations\n",
        "   - Cities with maximum passenger arrivals and departures\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import datetime\n",
        "import shutil\n",
        "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
        "import time\n",
        "import multiprocessing\n",
        "from typing import Dict, List, Tuple, Union\n",
        "\n",
        "# Constants\n",
        "N = 5000  # Number of JSON files to generate\n",
        "M_MIN, M_MAX = 50, 100  # Range for number of flight records per file\n",
        "K = 150  # Number of cities\n",
        "L = 0.007  # Probability for NULL values\n",
        "OUTPUT_DIR = os.path.join(os.getcwd(), \"tmp\", \"flights_1\")\n",
        "\n",
        "\n",
        "# delete it if the directory already exists , checking this to ensure you generate a new sequence for testing\n",
        "if os.path.exists(OUTPUT_DIR):\n",
        "  shutil.rmtree(OUTPUT_DIR)\n",
        "# Ensure output directory exists\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSZ1m6oJrTma",
        "outputId": "899b984b-5bb7-47a8-8bce-b53cb72404cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Python_Scripts/Assignments/vertisystem/tmp/flights_1\n"
          ]
        }
      ],
      "source": [
        "print(OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBKLsQlmrBzw",
        "outputId": "6ef41e12-bf81-411c-98ca-3385ce5e4548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating 5000 JSON files...\n",
            "Analyzing files...\n",
            "Total records processed: 374852\n",
            "miss records: 2648\n",
            "Total run duration: 104.58 seconds\n",
            "\n",
            "AVG and P95 of flight duration for Top 25 destination cities:\n",
            "City_25: AVG = 18729.73 seconds, P95 = 34294.00 seconds\n",
            "City_90: AVG = 18986.49 seconds, P95 = 34389.00 seconds\n",
            "City_136: AVG = 18939.40 seconds, P95 = 34428.00 seconds\n",
            "City_109: AVG = 19074.32 seconds, P95 = 34222.00 seconds\n",
            "City_35: AVG = 19011.84 seconds, P95 = 34261.00 seconds\n",
            "City_63: AVG = 19200.48 seconds, P95 = 34553.00 seconds\n",
            "City_27: AVG = 18839.53 seconds, P95 = 34235.00 seconds\n",
            "City_75: AVG = 18941.06 seconds, P95 = 34151.00 seconds\n",
            "City_16: AVG = 18656.44 seconds, P95 = 34293.00 seconds\n",
            "City_8: AVG = 18775.65 seconds, P95 = 34236.00 seconds\n",
            "City_21: AVG = 19014.55 seconds, P95 = 34336.00 seconds\n",
            "City_60: AVG = 18815.46 seconds, P95 = 34212.00 seconds\n",
            "City_79: AVG = 19101.40 seconds, P95 = 34322.00 seconds\n",
            "City_68: AVG = 18744.95 seconds, P95 = 34246.00 seconds\n",
            "City_18: AVG = 19057.76 seconds, P95 = 34375.00 seconds\n",
            "City_127: AVG = 19068.30 seconds, P95 = 34344.00 seconds\n",
            "City_24: AVG = 18793.88 seconds, P95 = 34179.00 seconds\n",
            "City_73: AVG = 18884.94 seconds, P95 = 34595.00 seconds\n",
            "City_83: AVG = 18570.39 seconds, P95 = 34094.00 seconds\n",
            "City_4: AVG = 18783.01 seconds, P95 = 34336.00 seconds\n",
            "City_3: AVG = 18918.48 seconds, P95 = 34283.00 seconds\n",
            "City_77: AVG = 18949.21 seconds, P95 = 34240.00 seconds\n",
            "City_118: AVG = 18655.56 seconds, P95 = 34191.00 seconds\n",
            "City_145: AVG = 18901.48 seconds, P95 = 34248.00 seconds\n",
            "City_125: AVG = 18797.08 seconds, P95 = 34274.00 seconds\n",
            "\n",
            "City with max passengers arrived: City_109 (455446 passengers)\n",
            "City with max passengers left: City_42 (455349 passengers)\n"
          ]
        }
      ],
      "source": [
        "# Generate a list of city names\n",
        "cities = [f\"City_{i}\" for i in range(K)]\n",
        "\n",
        "def generate_flight_record() -> Dict[str, Union[str, int, None]]:\n",
        "    \"\"\"\n",
        "    Generate a single flight record with random data.\n",
        "\n",
        "    This function creates a dictionary representing a flight record with the following fields:\n",
        "    - date: ISO format date string (YYYY-MM-DD)\n",
        "    - origin_city: Randomly selected city name from the 'cities' list\n",
        "    - destination_city: Randomly selected city name (different from origin) from the 'cities' list\n",
        "    - flight_duration_secs: Random integer between 1800 and 36000 (30 minutes to 10 hours)\n",
        "    - passengers_on_board: Random integer between 50 and 300\n",
        "\n",
        "    There's a small probability (L) that one of the fields will be set to None to simulate incomplete data\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Union[str, int, None]]: A dictionary containing the following key-value pairs:\n",
        "            - 'date': str\n",
        "            - 'origin_city': str\n",
        "            - 'destination_city': str\n",
        "            - 'flight_duration_secs': int\n",
        "            - 'passengers_on_board': int\n",
        "            Any of these values may be None with probability L.\n",
        "\n",
        "    Example:\n",
        "        >>> record = generate_flight_record()\n",
        "        >>> print(record)\n",
        "        {'date': '2024-06-15', 'origin_city': 'City_42', 'destination_city': 'City_78',\n",
        "         'flight_duration_secs': 7200, 'passengers_on_board': 180}\n",
        "    \"\"\"\n",
        "    origin, destination = random.sample(cities, 2)\n",
        "    date = datetime.date(2024, random.randint(1, 12), random.randint(1, 28))\n",
        "    duration = random.randint(1800, 36000)  # 30 minutes to 10 hours\n",
        "    passengers = random.randint(50, 300)\n",
        "\n",
        "    record = {\n",
        "        \"date\": date.isoformat(),\n",
        "        \"origin_city\": origin,\n",
        "        \"destination_city\": destination,\n",
        "        \"flight_duration_secs\": duration,\n",
        "        \"passengers_on_board\": passengers\n",
        "    }\n",
        "\n",
        "    # Introduce NULL values with probability L\n",
        "    if random.random() < L:\n",
        "        key = random.choice(list(record.keys()))\n",
        "        record[key] = None\n",
        "\n",
        "    return record\n",
        "\n",
        "def generate_json_chunk(chunk_size: int) -> List[Dict[str, Union[str, int, None]]]:\n",
        "    \"\"\"\n",
        "    Generate a chunk of flight records.\n",
        "\n",
        "    This function creates a list of flight records by calling the generate_flight_record()\n",
        "    function multiple times\n",
        "    It's used as part of the divide-and-conquer approach for generating large datasets\n",
        "\n",
        "    Args:\n",
        "        chunk_size (int): The no. of flight records to generate in this chunk.\n",
        "\n",
        "    Returns:\n",
        "        List[Dict[str, Union[str, int, None]]]: A list of dictionaries, where each dictionary\n",
        "        represents a flight record with the structure defined in generate_flight_record()\n",
        "\n",
        "    Raises:\n",
        "        AssertionError: If chunk_size is not a positive integer\n",
        "\n",
        "    Example:\n",
        "        >>> chunk = generate_json_chunk(5)\n",
        "        >>> print(len(chunk))\n",
        "        5\n",
        "        >>> print(chunk[0].keys())\n",
        "        dict_keys(['date', 'origin_city', 'destination_city', 'flight_duration_secs', 'passengers_on_board'])\n",
        "    \"\"\"\n",
        "    assert isinstance(chunk_size, int) and chunk_size > 0, \"chunk_size must be a positive integer\"\n",
        "    return [generate_flight_record() for _ in range(chunk_size)]\n",
        "\n",
        "def generate_json_file(file_number: int) -> None:\n",
        "    \"\"\"\n",
        "    Generate a JSON file with flight records.\n",
        "\n",
        "    This function creates a single JSON file containing a random no. of flight records\n",
        "    (between M_MIN and M_MAX). The file is named using the format:\n",
        "    \"MM-YY-OriginCity-flights-FileNumber.json\"\n",
        "\n",
        "    Args:\n",
        "        file_number (int): The no. of the file being generated, used in the filename\n",
        "\n",
        "    Raises:\n",
        "        AssertionError: If file_number is not a non-negative integer\n",
        "        IOError: If there's an error writing to the file\n",
        "\n",
        "    Example:\n",
        "        >>> generate_json_file(42)\n",
        "        # Creates a file like \"08-24-City_56-flights-42.json\" in the OUTPUT_DIR\n",
        "    \"\"\"\n",
        "    assert isinstance(file_number, int) and file_number >= 0, \"file_number must be a non-negative integer\"\n",
        "\n",
        "    month = random.randint(1, 12)\n",
        "    year = 24\n",
        "    origin_city = random.choice(cities)\n",
        "    filename = f\"{OUTPUT_DIR}/{month:02d}-{year:02d}-{origin_city}-flights-{file_number}.json\"\n",
        "\n",
        "    chunk_size = random.randint(M_MIN, M_MAX)\n",
        "    records = generate_json_chunk(chunk_size)\n",
        "\n",
        "    try:\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(records, f)\n",
        "    except IOError as e:\n",
        "        print(f\"Error writing to file {filename}: {e}\")\n",
        "        raise\n",
        "\n",
        "def process_file(filename: str) -> Dict[str, Union[int, Dict]]:\n",
        "    \"\"\"\n",
        "    Process a single file and return its statistics\n",
        "\n",
        "    This function reads a JSON file of flight records and computes various statistics:\n",
        "    - Total no. of records\n",
        "    - No. of \"miss\" (incomplete) records\n",
        "    - Flight durations for each destination\n",
        "    - Passenger counts for arrivals and departures for each city\n",
        "\n",
        "    Args:\n",
        "        filename (str): The name of the file to process\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Union[int, Dict]]: A dictionary containing the following key-value pairs:\n",
        "            - 'total_records': int\n",
        "            - 'miss_records': int\n",
        "            - 'flight_durations': Dict[str, List[int]]\n",
        "            - 'city_passengers': Dict[str, Dict[str, int]]\n",
        "\n",
        "    Raises:\n",
        "        AssertionError: If filename is not a string.\n",
        "        FileNotFoundError: If the specified file does not exist.\n",
        "        json.JSONDecodeError: If the file contains invalid JSON.\n",
        "\n",
        "    Example:\n",
        "        >>> stats = process_file('08-24-City_56-flights-42.json')\n",
        "        >>> print(stats['total_records'])\n",
        "        75\n",
        "    \"\"\"\n",
        "    assert isinstance(filename, str), \"filename must be a string\"\n",
        "\n",
        "    try:\n",
        "        with open(os.path.join(OUTPUT_DIR, filename), 'r') as f:\n",
        "            records = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {filename}\")\n",
        "        raise\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Invalid JSON in file: {filename}\")\n",
        "        raise\n",
        "\n",
        "    file_stats = {\n",
        "        'total_records': len(records),\n",
        "        'miss_records': 0,\n",
        "        'flight_durations': {},\n",
        "        'city_passengers': {city: {\"arrived\": 0, \"left\": 0} for city in cities}\n",
        "    }\n",
        "\n",
        "    for record in records:\n",
        "        if None in record.values():\n",
        "            file_stats['miss_records'] += 1\n",
        "        else:\n",
        "            dest = record[\"destination_city\"]\n",
        "            if dest not in file_stats['flight_durations']:\n",
        "                file_stats['flight_durations'][dest] = []\n",
        "            file_stats['flight_durations'][dest].append(record[\"flight_duration_secs\"])\n",
        "\n",
        "            file_stats['city_passengers'][record[\"origin_city\"]][\"left\"] += record[\"passengers_on_board\"]\n",
        "            file_stats['city_passengers'][record[\"destination_city\"]][\"arrived\"] += record[\"passengers_on_board\"]\n",
        "\n",
        "    return file_stats\n",
        "\n",
        "def merge_stats(stats_list: List[Dict[str, Union[int, Dict]]]) -> Dict[str, Union[int, Dict]]:\n",
        "    \"\"\"\n",
        "    Merge statistics from multiple files.\n",
        "\n",
        "    This function takes a list of statistics dictionaries (one for each processed file)\n",
        "    and merges them into a single dictionary of combined statistics.\n",
        "\n",
        "    Args:\n",
        "        stats_list (List[Dict[str, Union[int, Dict]]]): A list of statistics dictionaries from processed files.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Union[int, Dict]]: A dictionary containing the following key-value pairs:\n",
        "            - 'total_records': int\n",
        "            - 'miss_records': int\n",
        "            - 'flight_durations': Dict[str, List[int]]\n",
        "            - 'city_passengers': Dict[str, Dict[str, int]]\n",
        "\n",
        "    Raises:\n",
        "        AssertionError: If stats_list is not a list or if any item in the list is not a dictionary.\n",
        "\n",
        "    Example:\n",
        "        >>> stats1 = {'total_records': 100, 'miss_records': 5, ...}\n",
        "        >>> stats2 = {'total_records': 150, 'miss_records': 7, ...}\n",
        "        >>> merged = merge_stats([stats1, stats2])\n",
        "        >>> print(merged['total_records'])\n",
        "        250\n",
        "    \"\"\"\n",
        "    assert isinstance(stats_list, list), \"stats_list must be a list\"\n",
        "    assert all(isinstance(stats, dict) for stats in stats_list), \"All items in stats_list must be dictionaries\"\n",
        "\n",
        "    merged_stats = {\n",
        "        'total_records': 0,\n",
        "        'miss_records': 0,\n",
        "        'flight_durations': {},\n",
        "        'city_passengers': {city: {\"arrived\": 0, \"left\": 0} for city in cities}\n",
        "    }\n",
        "\n",
        "    for stats in stats_list:\n",
        "        merged_stats['total_records'] += stats['total_records']\n",
        "        merged_stats['miss_records'] += stats['miss_records']\n",
        "\n",
        "        for dest, durations in stats['flight_durations'].items():\n",
        "            if dest not in merged_stats['flight_durations']:\n",
        "                merged_stats['flight_durations'][dest] = []\n",
        "            merged_stats['flight_durations'][dest].extend(durations)\n",
        "\n",
        "        for city, passengers in stats['city_passengers'].items():\n",
        "            merged_stats['city_passengers'][city][\"arrived\"] += passengers[\"arrived\"]\n",
        "            merged_stats['city_passengers'][city][\"left\"] += passengers[\"left\"]\n",
        "\n",
        "    return merged_stats\n",
        "\n",
        "def analyze_files() -> Tuple[int, int, Dict[str, Dict[str, float]], Tuple[str, Dict[str, int]], Tuple[str, Dict[str, int]]]:\n",
        "    \"\"\"\n",
        "    Analyze the generated JSON files using parallel processing.\n",
        "\n",
        "    This function reads all JSON files in the OUTPUT_DIR, processes them in parallel,\n",
        "    and computes various statistics about the flight data.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[int, int, Dict[str, Dict[str, float]], Tuple[str, Dict[str, int]], Tuple[str, Dict[str, int]]]:\n",
        "            - total_records (int): Total number of records processed across all files.\n",
        "            - miss_records (int): Total number of incomplete records across all files.\n",
        "            - stats (Dict[str, Dict[str, float]]): Dictionary of flight duration stats for top 25 destinations.\n",
        "              Each destination has 'avg' and 'p95' keys with float values.\n",
        "            - max_arrived (Tuple[str, Dict[str, int]]): Tuple containing the city name (str) with max arrived passengers\n",
        "              and a dictionary with 'arrived' and 'left' passenger counts (int).\n",
        "            - max_left (Tuple[str, Dict[str, int]]): Tuple containing the city name (str) with max departed passengers\n",
        "              and a dictionary with 'arrived' and 'left' passenger counts (int).\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the OUTPUT_DIR does not exist or is empty.\n",
        "\n",
        "    Example:\n",
        "        >>> total, miss, stats, max_arr, max_dep = analyze_files()\n",
        "        >>> print(f\"Total records: {total}, miss records: {miss}\")\n",
        "        Total records: 375000, miss records: 2625\n",
        "        >>> print(stats['City_1'])\n",
        "        {'avg': 18360.25, 'p95': 32400.00}\n",
        "        >>> print(max_arr)\n",
        "        ('City_78', {'arrived': 1500000, 'left': 1480000})\n",
        "    \"\"\"\n",
        "    filenames = os.listdir(OUTPUT_DIR)\n",
        "    if not filenames:\n",
        "        raise FileNotFoundError(f\"No files found in {OUTPUT_DIR}\")\n",
        "\n",
        "    # Use ProcessPoolExecutor for parallel file processing\n",
        "    with ProcessPoolExecutor(max_workers=multiprocessing.cpu_count()) as executor:\n",
        "        stats_list = list(executor.map(process_file, filenames))\n",
        "\n",
        "    # Merge the results\n",
        "    merged_stats = merge_stats(stats_list)\n",
        "\n",
        "    total_records = merged_stats['total_records']\n",
        "    miss_records = merged_stats['miss_records']\n",
        "\n",
        "    # Calculate AVG and P95 for top 25 destination cities\n",
        "    flight_durations = merged_stats['flight_durations']\n",
        "    top_25_destinations = sorted(flight_durations.items(), key=lambda x: len(x[1]), reverse=True)[:25]\n",
        "    stats = {}\n",
        "    for dest, durations in top_25_destinations:\n",
        "        avg = sum(durations) / len(durations)\n",
        "        p95 = sorted(durations)[int(len(durations) * 0.95)]\n",
        "        stats[dest] = {\"avg\": avg, \"p95\": p95}\n",
        "\n",
        "    # Find cities with max passengers arrived and left\n",
        "    city_passengers = merged_stats['city_passengers']\n",
        "    max_arrived = max(city_passengers.items(), key=lambda x: x[1][\"arrived\"])\n",
        "    max_left = max(city_passengers.items(), key=lambda x: x[1][\"left\"])\n",
        "\n",
        "    return total_records, miss_records, stats, max_arrived, max_left\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "        \"\"\"\n",
        "        Main function to run the entire data generation and analysis pipeline.\n",
        "\n",
        "        This function orchestrates the entire process:\n",
        "        1. Generates N JSON files containing flight records using multi-threading\n",
        "        2. Analyzes the generated files to extract statistics using parallel processing\n",
        "        3. Prints the results of the analysis\n",
        "\n",
        "        The function also measures and reports the total execution time.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "\n",
        "        Raises:\n",
        "            Exception: If any error occurs during the execution of the pipeline.\n",
        "\n",
        "        Example:\n",
        "            >>> main()\n",
        "            Generating 5000 JSON files...\n",
        "            Analyzing files...\n",
        "            Total records processed: 375000\n",
        "            miss records: 2625\n",
        "            Total run duration: 45.23 seconds\n",
        "            ...\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            # Generation phase\n",
        "            print(f\"Generating {N} JSON files...\")\n",
        "            with ThreadPoolExecutor(max_workers=multiprocessing.cpu_count() * 2) as executor:\n",
        "                list(executor.map(generate_json_file, range(N)))\n",
        "\n",
        "            # Analysis phase\n",
        "            print(\"Analyzing files...\")\n",
        "            total_records, miss_records, flight_stats, max_arrived, max_left = analyze_files()\n",
        "\n",
        "            end_time = time.time()\n",
        "            total_duration = end_time - start_time\n",
        "\n",
        "            # Print results\n",
        "            print(f\"Total records processed: {total_records}\")\n",
        "            print(f\"miss records: {miss_records}\")\n",
        "            print(f\"Total run duration: {total_duration:.2f} seconds\")\n",
        "\n",
        "            print(\"\\nAVG and P95 of flight duration for Top 25 destination cities:\")\n",
        "            for dest, stats in flight_stats.items():\n",
        "                print(f\"{dest}: AVG = {stats['avg']:.2f} seconds, P95 = {stats['p95']:.2f} seconds\")\n",
        "\n",
        "            print(f\"\\nCity with max passengers arrived: {max_arrived[0]} ({max_arrived[1]['arrived']} passengers)\")\n",
        "            print(f\"City with max passengers left: {max_left[0]} ({max_left[1]['left']} passengers)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during execution: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "        main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
